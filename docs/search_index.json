[
["solución-de-sistemas-de-ecuaciones-lineales.html", "3 Solución de Sistemas de Ecuaciones Lineales 3.1 Generalidades 3.2 Repaso 3.3 Notación 3.4 Métodos de Resolución de Sistemas de Ecuaciones 3.5 Sistemas fáciles de resolver 3.6 Eliminación gaussiana 3.7 Estrategias de pivoteo para reducir los errores 3.8 Método de eliminación de Gauss-Jordan 3.9 Métodos Aproximados o Iterativos", " 3 Solución de Sistemas de Ecuaciones Lineales 3.1 Generalidades Objetivo: examinar los aspectos numéricos que se presentan al resolver sistemas de ecuaciones lineales de la forma: \\[ \\begin{cases} a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n = b_1 \\\\ a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n = b_2 \\\\ \\vdots \\\\ a_{n1}x_1 + a_{n2}x_2 + \\cdots + a_{nn}x_n = b_n \\end{cases} \\] \\(n\\) ecuaciones, \\(n\\) incógnitas: sistema de orden \\(n \\times n\\). Los coeficientes \\(a_{ij}\\) y los términos independientes \\(b_i\\) son reales fijos. 3.2 Repaso Representación matricial: \\(\\mathbf{Ax=b}\\), de dimensión \\(n\\times n\\), \\(n\\times 1\\) y \\(n\\times 1\\), respectivamente. \\[ \\begin{bmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1} &amp; a_{n2} &amp; \\cdots &amp; a_{nn} \\end{bmatrix} \\times \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix} \\] Llamamos matriz ampliada o aumentada a: \\[ \\begin{bmatrix} \\mathbf{A} &amp; \\mathbf{b} \\end{bmatrix} = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} &amp; b_1\\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2n} &amp; b_2\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots\\\\ a_{n1} &amp; a_{n2} &amp; \\cdots &amp; a_{nn} &amp; b_n \\end{bmatrix} \\] Un sistema de ecuaciones lineales se clasifica en: Compatible determinado: tiene una única solución Compatible indeterminado: tiene infinitas soluciones Incompatible: no existe solución Teorema. Las siguientes condiciones son equivalentes: El sistema \\(\\mathbf{Ax=b}\\) tiene solución única (es compatible determinado). La matriz \\(\\mathbf{A}\\) es invertible (existe \\(\\mathbf{A^{-1}}\\)). La matriz \\(\\mathbf{A}\\) es no singular (\\(\\det \\mathbf{A} \\neq 0\\)). El sistema \\(\\mathbf{Ax=0}\\) tiene como única solución \\(\\mathbf{x=0}\\). Dos sistemas de orden \\(n \\times n\\) son equivalentes si tienen el mismo conjunto de soluciones. Existen ciertas transformaciones sobre las ecuaciones de un sistema que no cambian el conjunto de soluciones (producen un sistema equivalente): Intercambio: el orden de las ecuaciones puede cambiarse. Escalado: multiplicar una ecuación por una constante no nula. Sustitución: una ecuación puede ser reemplazada por una combinación lineal de las ecuaciones del sistema (teorema fundamental de la equivalencia) Realizar estas transformaciones sobre las ecuaciones es equivalente a realizar las mismas operaciones sobre las filas de la matriz aumentada. 3.3 Notación En esta sección presentamos la notación utilizaremos para expresar algoritmos con operaciones matriciales, facilitando su traducción a IML o R. Dada una matriz \\(\\mathbf{Z}\\) de dimensión \\(n \\times m\\), anotamos: \\(z_{ij} = \\mathbf{Z}[i, j]\\): elemento en la fila \\(i\\) y columna \\(j\\) de la matriz \\(\\mathbf{Z}\\) \\(\\mathbf{Z}[i,]\\): vector fila de dimensión \\(1\\times m\\) constituido por la \\(i\\)-ésima fila de la matriz \\(\\mathbf{Z}\\) \\(\\mathbf{Z}[,j]\\): vector columna \\(n\\times 1\\) constituido por la \\(j\\)-ésima columna de la matriz \\(\\mathbf{Z}\\) \\(\\mathbf{Z}[i,k:l]\\): matriz de dimensión \\(1\\times (l-k+1)\\) constituida con los elementos \\(z_{i,k}, z_{i,k+1}, \\cdots, z_{i,l}\\) de la matriz \\(\\mathbf{Z}\\), \\(l \\geq k\\). \\(\\mathbf{Z}[c:d,k:l]\\): matriz de dimensión \\((d-c+1)\\times (l-k+1)\\) constituida por la submatriz que contiene las filas de \\(\\mathbf{Z}\\) desde la \\(c\\) hasta \\(d\\) y las columnas de \\(\\mathbf{Z}\\) desde la \\(k\\) hasta la \\(l\\), \\(d \\geq c\\), \\(l \\geq k\\). Dado un vector \\(\\mathbf{Z}\\) de largo \\(n\\), anotamos: \\(\\mathbf{Z}[i]\\): elemento \\(i\\)-ésimo del vector \\(\\mathbf{Z}\\) \\(\\mathbf{Z}[k:l]\\): vector de largo \\((l-k+1)\\) constituido con los elementos \\(z_{k}, z_{k+1}, \\cdots, z_{l}\\) del vector \\(\\mathbf{Z}\\), \\(l \\geq k\\). 3.4 Métodos de Resolución de Sistemas de Ecuaciones Métodos exactos: permiten obtener la solución del sistema de manera directa. Método de Eliminación de Gauss Método de Gauss-Jordan Métodos aproximados: utilizan algoritmos iterativos que calculan las solución del sistema por aproximaciones sucesivas. Método de Jacobi Método de Gauss-Seidel En muchas ocasiones los métodos aproximados permiten obtener un grado de exactitud superior al que se puede obtener empleando los denominados métodos exactos, debido fundamentalmente a los errores de truncamiento que se producen en el proceso. 3.5 Sistemas fáciles de resolver Caso 1: La matriz \\(\\mathbf{A}\\) es diagonal \\[ \\begin{bmatrix} a_{11} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; a_{22} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{nn} \\end{bmatrix} \\times \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix} \\] El sistema se reduce a \\(n\\) ecuaciones simples y la solución es: \\[ \\mathbf{x} = \\begin{bmatrix} b_1/a_{11} \\\\ b_2/a_{22} \\\\ \\vdots \\\\ b_n/a_{nn} \\end{bmatrix} \\] Caso 2: La matrix \\(\\mathbf{A}\\) es triangular superior: \\[ \\begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp; \\cdots &amp; a_{1n} \\\\ 0 &amp; a_{22} &amp; a_{23} &amp; \\cdots &amp; a_{2n} \\\\ 0 &amp; 0 &amp; a_{33} &amp; \\cdots &amp; a_{3n} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; a_{nn} \\end{bmatrix} \\times \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix} \\] La solución de \\(x_n\\) es inmediata y a partir de ella se encuentran las restantes en orden inverso \\(x_{n-1}, \\cdots, x_1\\), aplicando el algoritmo de sustitución regresiva: \\[ x_n = \\frac{b_n}{a_{nn}} \\text{ y } x_k = \\frac{b_k - \\sum_{j = k+1}^{n}a_{kj}x_j}{a_{kk}} \\quad k = n-1, n-2, \\cdots, 1 \\] Empleando la notación matricial vista, la suma en el algoritmo puede reescribirse con productos matriciales: \\[ \\mathbf{x}[n] = \\frac{\\mathbf{b}[n]}{\\mathbf{A}[n,n]} \\qquad \\mathbf{x}[k] = \\frac{\\mathbf{b}[k] - \\mathbf{A}[k, k+1 : n] \\times \\mathbf{x}[k+1 : n]}{\\mathbf{A}[k,k]} \\] \\[ \\quad k = n-1, n-2, \\cdots, 1 \\] Iniciando el vector solución con ceros, \\(\\mathbf{x} = [0 ~ 0 \\cdots 0]\\), la expresión anterior se simplifica como: \\[ \\mathbf{x}[n] = \\frac{\\mathbf{b}[n]}{\\mathbf{A}[n,n]} \\qquad \\mathbf{x}[k] = \\frac{\\mathbf{b}[k] - \\mathbf{A}[k, ] \\times \\mathbf{x}}{\\mathbf{A}[k,k]} \\qquad k = n-1, n-2, \\cdots, 1 \\] Tarea: ver el algoritmo en documento adjunto y programarlo. Caso 3: La matrix \\(\\mathbf{A}\\) es triangular inferior: Obtención de la solución análoga al caso anterior. Observaciones En los casos anteriores asumimos \\(a_{kk} \\neq 0 \\quad \\forall \\quad k\\). De lo contrario el sistema no tiene solución o tiene infinitas. Recordar que un sistema lineal \\(\\mathbf{Ax=b}\\) tiene solución única si y sólo si \\(\\det \\mathbf{A} \\neq 0\\) y que si un elemento de la diagonal principal de una matriz triangular es cero, entonces \\(\\det \\mathbf{A} = 0\\). 3.6 Eliminación gaussiana Es un método para resolver un sistema lineal general \\(\\mathbf{Ax=b}\\) de \\(n\\) ecuaciones con \\(n\\) incógnitas. El objetivo es construir un sistema equivalente donde la matriz de coeficientes sea triangular superior para obtener las soluciones con el algoritmo de sustitución regresiva. El método consiste en ir eliminando incógnitas en las ecuaciones de manera sucesiva. Ejemplo: resolver el siguiente sistema \\[ \\begin{cases} x+2y-z+3t=-8 \\\\ 2x+2z-t=13 \\\\ -x+y+z-t=8\\\\ 3x+3y-z+2t = -1 \\end{cases} \\mathbf{A}= \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 \\\\ 2 &amp; 0 &amp; 2 &amp; -1 \\\\ -1 &amp; 1 &amp; 1 &amp; -1 \\\\ 3 &amp; 3 &amp; -1 &amp; 2 &amp; \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix} x \\\\ y \\\\ z \\\\ t \\end{bmatrix} \\mathbf{b} = \\begin{bmatrix} -8 \\\\ 13 \\\\ 8 \\\\ -1 \\end{bmatrix} \\] Matriz aumentada: \\[ \\begin{bmatrix} \\mathbf{A} &amp; \\mathbf{b} \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 2 &amp; 0 &amp; 2 &amp; -1 &amp;|&amp; 13\\\\ -1 &amp; 1 &amp; 1 &amp; -1 &amp;|&amp; 8\\\\ 3 &amp; 3 &amp; -1 &amp; 2 &amp;|&amp; -1 \\end{bmatrix} \\] En el primer paso eliminamos la incógnita \\(x\\) en las ecuaciones 2, 3 y 4, buscando que queden ceros en toda la primera columna excepto en el elemento diagonal. La eliminación se hace empleando las transformaciones que producen un sistema equivalente. Observando con detenimiento, esto se puede lograr realizando los siguientes reemplazos: \\[ \\begin{array}{cl} \\text{Fila 2} &amp;= \\text{ Fila 2} - 2 \\times \\text{Fila 1} \\\\ \\text{Fila 3} &amp;= \\text{ Fila 3} - (-1) \\times \\text{Fila 1} \\\\ \\text{Fila 4} &amp;= \\text{ Fila 4} - 3 \\times \\text{Fila 1} \\end{array} \\] A la Fila 1 se le dice fila pivote y al elemento \\(a_{11}=1\\), pivote. A los valores \\(2\\), \\(-1\\) y \\(3\\) que multiplican a la fila pivote en los reemplazos se les dice multiplicadores. De manera general, los multiplicadores se simbolizan y obtienen con: \\[m_{r1} = a_{r1} / a_{11}, \\quad r = 2, 3, ..., n\\] De esta forma, los reemplazos realizados se generalizan como: \\[\\text{Fila } r = \\text{Fila } r - m_{r1} \\times \\text{Fila 1}\\] - El resultado de los reemplazos anteriores es: \\[ \\begin{matrix} \\text{pivote} \\rightarrow \\\\ m_{21} = 2 \\\\ m_{31} = -1 \\\\ m_{41} = 3 \\end{matrix} \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 2 &amp; 0 &amp; 2 &amp; -1 &amp;|&amp; 13\\\\ -1 &amp; 1 &amp; 1 &amp; -1 &amp;|&amp; 8\\\\ 3 &amp; 3 &amp; -1 &amp; 2 &amp;|&amp; -1 \\end{bmatrix} \\implies \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 0 &amp; -4 &amp; 4 &amp; -7 &amp;|&amp; 29\\\\ 0 &amp; 3 &amp; 0 &amp; 2 &amp;|&amp; 0\\\\ 0 &amp; -3 &amp; 2 &amp; -7 &amp;|&amp; 23 \\end{bmatrix} \\] En el segundo paso, eliminamos la incógnita \\(y\\) en las ecuaciones 3 y 4. La fila pivote pasa a ser la segunda y el pivote es \\(a_{22}=-4\\). Los multiplicadores son \\(m_{r2}=a_{r2}/a_{22}\\), \\(r=3,4\\), dando lugar a los reemplazos: \\[ \\begin{array}{cl} \\text{Fila 3} &amp;= \\text{ Fila 3} - (-3/4) \\times \\text{Fila 2} \\\\ \\text{Fila 4} &amp;= \\text{ Fila 4} - 3/4 \\times \\text{Fila 2} \\end{array} \\] El resultado es: \\[ \\begin{matrix} \\\\ \\text{pivote} \\rightarrow \\\\ m_{32} = -3/4 \\\\ m_{42} = 3/4 \\end{matrix} \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 0 &amp; -4 &amp; 4 &amp; -7 &amp;|&amp; 29\\\\ 0 &amp; 3 &amp; 0 &amp; 2 &amp;|&amp; 0\\\\ 0 &amp; -3 &amp; 2 &amp; -7 &amp;|&amp; 23 \\end{bmatrix} \\implies \\] \\[ \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 0 &amp; -4 &amp; 4 &amp; -7 &amp;|&amp; 29\\\\ 0 &amp; 0 &amp; -12 &amp; 13 &amp;|&amp; -87\\\\ 0 &amp; 0 &amp; 4 &amp; 7 &amp;|&amp; -5 \\end{bmatrix} \\] Finalmente, eliminamos la incógnita \\(z\\) en la última ecuación. La fila pivote es la 3º y el pivote es \\(a_{33}=-12\\). El multiplicador es \\(m_{43}=a_{43}/a_{33}=-4/12\\). El reemplazo a realizar es: \\[\\text{Fila } 4 = \\text{Fila } 4 - (-4/12) \\times \\text{Fila } 3\\] El resultado es: \\[ \\begin{matrix} \\\\ \\\\ \\text{pivote} \\rightarrow \\\\ m_{43} = -4/12 \\end{matrix} \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 0 &amp; -4 &amp; 4 &amp; -7 &amp;|&amp; 29\\\\ 0 &amp; 0 &amp; -12 &amp; 13 &amp;|&amp; -87\\\\ 0 &amp; 0 &amp; 4 &amp; 7 &amp;|&amp; -5 \\end{bmatrix} \\implies \\] \\[ \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 0 &amp; -4 &amp; 4 &amp; -7 &amp;|&amp; 29\\\\ 0 &amp; 0 &amp; -12 &amp; 13 &amp;|&amp; -87\\\\ 0 &amp; 0 &amp; 0 &amp; -136 &amp;|&amp; 408 \\end{bmatrix} \\] Hemos llegado a un sistema equivalente cuya matriz de coeficientes es triangular superior, en el que aplicamos el algoritmo de sustitución regresiva: \\[ \\left\\{ \\begin{aligned} x+2y-z-3t &amp;=-8 \\cr -4y+4z-7t &amp;=29\\cr -12z+13t &amp;=-87\\cr -136t &amp;=408 \\end{aligned} \\right. \\implies \\left\\{ \\begin{aligned} x &amp;= 1\\\\ y &amp;= 2\\\\ z &amp;= 4\\\\ t &amp;= -3 \\end{aligned} \\right. \\] Tarea: revisar el algoritmo y la función ya programada. 3.6.1 Eliminación gaussiana con pivoteo trivial En el algoritmo anterior es necesario que los pivotes \\(a_{qq} \\neq 0 ~\\forall q\\). Si en uno de los pasos encontramos un \\(a_{qq} = 0\\), debemos intercambiar la \\(q\\)-ésima fila por una cualquiera de las siguientes, por ejemplo la fila \\(k\\), en la que \\(a_{kq} \\neq 0, k&gt;q\\). Esta estrategia para hallar un pivote no nulo se llama pivoteo trivial. Tarea: verificar “a mano” que con el siguiente sistema, si seguimos el algoritmo anterior, incurrimos en este problema. En cambio, si seguimos el algoritmo con pivoteo trivial (ver en documento adjunto y su programa) no tenemos dicho problema. \\[ \\begin{cases} x-2y+z=-4 \\\\ -2x+4y-3z=3 \\\\ x-3y-4z=-1 \\end{cases} \\] 3.7 Estrategias de pivoteo para reducir los errores Como ya sabemos, dado que las computadoras usan una aritmética cuya precisión está fijada de antemano, es posible que cada vez que se realice una operación aritmética se introduzca un pequeño error. En la resolución de ecuaciones por eliminación gaussiana, un adecuado reordenamiento de las filas en el momento indicado puede reducir notablemente los errores cometidos. Por ejemplo, se puede mostrar cómo buscar un multiplicador de menor magnitud (es decir, un pivote de mayor magnitud) mejora la precisión de los resultados. Por eso, existen estrategias de pivoteo que no solamente hacen intercambio de filas cuando se tiene un pivote nulo, si no también cuando alguna de las filas posteriores tiene un pivote de mayor valor absoluto. 3.7.1 Pivoteo parcial Para reducir la propagación de los errores de redondeo, antes de comenzar una nueva ronda de reemplazos con el pivote \\(a_{qq}\\) se evalúa si debajo en la misma columna hay algún elemento con mayor valor absoluto y en ese caso se intercambian las respectivas filas. Es decir, se busca si existe \\(r\\) tal que \\(|a_{rq}| &gt; |a_{qq}|,\\quad r&gt;q\\) para luego intercambiar las filas \\(q\\) y \\(r\\). Este proceso suele conservar las magnitudes relativas de los elementos de la matriz triangular superior en el mismo orden que las de los coeficientes de la matriz original. Tarea: leer el algoritmo del pivoteo parcial en el documento adjunto y programarlo. 3.7.2 Pivoteo parcial escalado Reduce aún más los efectos de la propagación de los errores. Se elige el elemento de la columna \\(q\\)-ésima, en o por debajo de la diagonal principal, que tiene mayor tamaño relativo con respecto al resto de los elementos de su fila. Paso 1: buscar el máximo valor absoluto en cada fila: \\[ s_r = max\\{|a_{rq}|, |a_{r,q+1}|, \\cdots, |a_{rn}| \\} \\quad r = q, q+1, \\cdots, n \\] Paso 2: elegir como fila pivote a la que tenga el mayor valor de \\(\\frac{|a_{rq}|}{s_r}\\), \\(r = q, q+1, \\cdots, n\\). Paso 3: intercambiar la fila \\(q\\) con la fila hallada en el paso 2. Tarea: leer el algoritmo del pivoteo parcial en el documento adjunto y programarlo. 3.8 Método de eliminación de Gauss-Jordan Ya vimos que el método de Gauss transforma la matriz de coeficientes en una matriz triangular superior. El método de Gauss-Jordan continúa el proceso de transformación hasta obtener la matriz identidad. En el ejemplo de la sección 3.6, cuando aplicamos eliminación de Gauss habíamos llegado a la siguiente matriz triangular: \\[ \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 0 &amp; -4 &amp; 4 &amp; -7 &amp;|&amp; 29\\\\ 0 &amp; 0 &amp; -12 &amp; 13 &amp;|&amp; -87\\\\ 0 &amp; 0 &amp; 0 &amp; -136 &amp;|&amp; 408 \\end{bmatrix} \\] Luego, con el método de sustitución regresiva, llegamos a encontrar \\(x=1\\), \\(y=2\\), \\(z=4\\) y \\(t=-3\\). En lugar de aplicar sustitución regresiva, seguimos operando por fila hasta lograr una matriz diagonal: \\[ \\begin{array}{cl} \\text{Fila 2} &amp;= \\text{ Fila 2} / (-4) \\\\ \\text{Fila 3} &amp;= \\text{ Fila 3} /(-12) \\\\ \\text{Fila 4} &amp;= \\text{ Fila 4} / (-136) \\end{array} \\implies \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 3 &amp;|&amp; -8\\\\ 0 &amp; 1 &amp; -1 &amp; 7/4 &amp;|&amp; -29/4\\\\ 0 &amp; 0 &amp; 1 &amp; -13/12 &amp;|&amp; 87/12\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp;|&amp; -3 \\end{bmatrix} \\] \\[ \\begin{array}{cl} \\text{Fila 1} &amp;= \\text{ Fila 1} - 3 \\text{ Fila 4} \\\\ \\text{Fila 2} &amp;= \\text{ Fila 2} - 7/4 \\text{ Fila 4}\\\\ \\text{Fila 3} &amp;= \\text{ Fila 3} + 13/12 \\text{ Fila 4} \\end{array} \\implies \\begin{bmatrix} 1 &amp; 2 &amp; -1 &amp; 0 &amp;|&amp; 1\\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp;|&amp; -2\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp;|&amp; 4\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp;|&amp; -3 \\end{bmatrix} \\] \\[ \\begin{array}{cl} \\text{Fila 1} &amp;= \\text{ Fila 1} + \\text{ Fila 3} \\\\ \\text{Fila 2} &amp;= \\text{ Fila 2} + \\text{ Fila 3} \\end{array} \\implies \\begin{bmatrix} 1 &amp; 2 &amp; 0 &amp; 0 &amp;|&amp; 5\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp;|&amp; 2\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp;|&amp; 4\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp;|&amp; -3 \\end{bmatrix} \\] \\[ \\begin{array}{cl} \\text{Fila 1} &amp;= \\text{ Fila 1} -2 \\text{ Fila 2} \\end{array} \\implies \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp;|&amp; 1\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp;|&amp; 2\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp;|&amp; 4\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp;|&amp; -3 \\end{bmatrix} \\] \\[ \\implies \\left\\{ \\begin{aligned} x &amp;= 1\\\\ y &amp;= 2\\\\ z &amp;= 4\\\\ t &amp;= -3 \\end{aligned} \\right. \\] La ventaja de este método es que permite también hallar fácilmente la matriz inversa de \\(\\mathbf{A}\\). Para esto hay que concatenar a la derecha de la matriz aumentada una matriz identidad de orden \\(n\\). Cuando en la submatriz izquierda se llega a la matriz identidad, en el centro habrá quedado el vector solución y a su derecha la matriz inversa. Ejemplo. Resolver el siguiente sistema y hallar la inversa de la matriz de coeficientes: \\[ \\begin{cases} x-y+z=-4 \\\\ 5x-4y+3z=-12 \\\\ 2x+y+z=11 \\end{cases} \\] \\[ \\begin{bmatrix} 1 &amp; -1 &amp; 1 &amp;|&amp; -4 &amp;|&amp; 1 &amp; 0 &amp; 0\\\\ 5 &amp; -4 &amp; 3 &amp;|&amp; -12 &amp;|&amp; 0 &amp; 1 &amp; 0\\\\ 2 &amp; 1 &amp; 1 &amp;|&amp; 11 &amp;|&amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] \\[ \\begin{array}{cl} F2 &amp;= F2 - 5 F1 \\\\ F3 &amp;= F3 - 2 F1 \\\\ F1 &amp;= F1 + F2 \\\\ F3 &amp;= F3 - 3 F2 \\\\ F1 &amp;= F1 + 1/5 F3 \\\\ F2 &amp;= F2 + 2/5 F3 \\\\ F3 &amp;= F3 / 5 \\end{array} \\] \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp;|&amp; 3 &amp;|&amp; -7/5 &amp; 2/5 &amp; 1/5\\\\ 0 &amp; 1 &amp; 0 &amp;|&amp; 6 &amp;|&amp; 1/5 &amp; -1/5 &amp; 2/5\\\\ 0 &amp; 0 &amp; 1 &amp;|&amp; -1 &amp;|&amp; 13/5 &amp; -3/2 &amp; 1/5 \\end{bmatrix} \\] ¿Por qué este procedimiento nos devuelva la inversa de la matriz de coeficientes? Recordar que la inversa de \\(\\mathbf{A}\\) es aquella matriz \\(\\mathbf{A}^{-1}\\) que verifica \\(\\mathbf{AA}^{-1} =\\mathbf{A}^{-1}\\mathbf{A}=\\mathbf{I}\\) Entonces si queremos hallar la matriz \\(\\mathbf{A}^{-1}\\): \\[ \\mathbf{A}^{-1} = \\begin{bmatrix} x_{11} &amp; x_{12} &amp; x_{13} \\\\ x_{21} &amp; x_{22} &amp; x_{23} \\\\ x_{31} &amp; x_{32} &amp; x_{33} \\end{bmatrix} \\] podemos plantear el siguiente producto matricial: \\[ \\begin{bmatrix} 1 &amp; -1 &amp; 1 \\\\ 5 &amp; -4 &amp; 3 \\\\ 2 &amp; 1 &amp; 1 \\end{bmatrix} \\times \\begin{bmatrix} x_{11} &amp; x_{12} &amp; x_{13} \\\\ x_{21} &amp; x_{22} &amp; x_{23} \\\\ x_{31} &amp; x_{32} &amp; x_{33} \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] que da lugar a tres sistemas de ecuaciones con la misma matriz de coeficientes: \\[ \\implies \\begin{bmatrix} x_{11}-x_{21}+x_{31} &amp; x_{12}-x_{22}+x_{32} &amp; x_{13}-x_{23}+x_{33} \\\\ 5x_{11}-4x_{21}+3x_{31} &amp; 5x_{12}-4x_{22}+3x_{32} &amp; 5x_{13}-4x_{23}+3x_{33} \\\\ 2x_{11}+x_{21}+x_{31} &amp; 2x_{12}-x_{22}+x_{32} &amp; 2x_{13}-x_{23}+x_{33} \\end{bmatrix} = \\] \\[ = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] \\[ \\begin{cases} x_{11}-x_{21}+x_{31}=1 \\\\ 5x_{11}-4x_{21}+3x_{31}=0 \\\\ 2x_{11}+x_{21}+x_{31}=0 \\end{cases} \\] \\[ \\begin{cases} x_{12}-x_{22}+x_{32}=0 \\\\ 5x_{12}-4x_{22}+3x_{32}=1 \\\\ 2x_{12}+x_{22}+x_{32}=0 \\end{cases} \\] \\[ \\begin{cases} x_{13}-x_{23}+x_{33}=0 \\\\ 5x_{13}-4x_{23}+3x_{33}=0 \\\\ 2x_{13}+x_{23}+x_{33}=1 \\end{cases} \\] Los resolvemos simultáneamente al agregarle a la matriz aumentada del sistema original, estos tres “nuevos vectores de términos independientes” que forman una matriz identidad de orden \\(n\\). En cierto modo, estamos resolviendo cuatro sistemas de ecuaciones a la vez, el sistema original y los tres que permiten hallar cada columna de \\(\\mathbf{A}^{-1}\\). Tarea. Revisar el algoritmo y programarlo. 3.9 Métodos Aproximados o Iterativos Objetivo: extender a espacios de dimensión mayor que 1 las ideas de los métodos iterativos vistos en la Unidad 2 para resolver sistemas de ecuaciones lineales. Veremos: Método de Jacobi Método de Gauss-Seidel 3.9.1 Método de Jacobi Consideremos el sistema: \\[ \\begin{cases} 4x-y+z=7 \\\\ 4x-8y+z=-21 \\\\ -2x+y+5z=15 \\end{cases} \\implies \\begin{cases} x=(7+y-z)/4 \\\\ y=(21+4x+z)/8 \\\\ z=(15+2x-y)/5 \\end{cases} \\] Despejar una incógnita en cada ecuación provee expresiones que sugieren la idea de un proceso iterativo. Dado un vector de valores iniciales \\(\\mathbf{x_0}=(x_0, y_0, z_0)\\), operar con la siguiente fórmula de recurrencia hasta la convergencia: \\[ \\begin{cases} x_{k+1}=(7+y_k-z_k)/4 \\\\ y_{k+1}=(21+4x_k+z_k)/8 \\\\ z_{k+1}=(15+2x_k-y_k)/5 \\end{cases} \\] Por ejemplo, tomando el valor inicial \\((1, 2, 2)\\), el proceso converge hacia la solución exacta del sistema \\((2, 4, 3)\\). Usando 4 posiciones decimales con redondeo luego de la coma: \\(k\\) \\(x_k\\) \\(y_k\\) \\(z_k\\) 0 1 2 2 1 1.7500 3.3750 3.0000 2 1.8438 3.8750 3.0250 3 1.9625 3.9250 2.9625 4 1.9906 3.9766 3.0000 5 1.9942 3.9953 3.0009 6 1.9986 3.9972 2.9986 7 1.9997 3.9991 3.0000 8 1.9998 3.9999 3.0001 9 2.0000 3.9999 2.9999 10 2.0000 4.0000 3.0000 Observación: no siempre este método converge. Es sensible al ordenamiento de las ecuaciones dentro del sistema. Ejemplo: tomamos el mismo sistema de antes pero intercambiamos las filas 1 y 3: \\[ \\begin{cases} 4x-y+z=7 \\\\ 4x-8y+z=-21 \\\\ -2x+y+5z=15 \\end{cases} \\implies \\begin{cases} -2x+y+5z=15 \\\\ 4x-8y+z=-21 \\\\ 4x-y+z=7 \\end{cases} \\] \\[ \\implies \\begin{cases} x=(-15+y+5z)/2 \\\\ y=(21+4x+z)/8 \\\\ z=7-4x+y \\end{cases} \\implies \\begin{cases} x_{k+1}=(-15+y_k+5z_k)/2 \\\\ y_{k+1}=(21+4x_k+z_k)/8 \\\\ z_{k+1}=7-4x_k+y_k \\end{cases} \\] Tomando el mismo valor inicial \\((1, 2, 2)\\), esta vez el proceso diverge: \\(k\\) \\(x_k\\) \\(y_k\\) \\(z_k\\) 0 1 2 2 1 -1.5000 3.3750 5.0000 2 6.6875 2.5000 16.3750 3 34.6875 8.0156 -17.2500 4 -46.6172 17.8125 -123.7344 5 -307.9298 -36.1504 211.2813 6 502.6281 -124.9297 1202.5688 7 2936.4572 404.2602 -2128.4421 8 -5126.4752 1204.7983 -11334.5686 9 -27741.5224 -3977.4337 21717.6991 10 52298.0309 -11153.4238 106995.6559 3.9.2 Método de Gauss-Seidel Toma la misma idea que Jacobi, pero con una pequeña modificación para acelerar la convergencia. Retomando el ejemplo inicial: \\[ \\begin{cases} 4x-y+z=7 \\\\ 4x-8y+z=-21 \\\\ -2x+y+5z=15 \\end{cases} \\implies \\begin{cases} x=(7+y-z)/4 \\\\ y=(21+4x+z)/8 \\\\ z=(15+2x-y)/5 \\end{cases} \\] Jacobi: \\[ \\begin{cases} x_{k+1}=(7+y_k-z_k)/4 \\\\ y_{k+1}=(21+4x_k+z_k)/8 \\\\ z_{k+1}=(15+2x_k-y_k)/5 \\end{cases} \\] Gauss-Seidel: \\[ \\begin{cases} x_{k+1}=(7+y_k-z_k)/4 \\\\ y_{k+1}=(21+4x_{k+1}+z_k)/8 \\\\ z_{k+1}=(15+2x_{k+1}-y_{k+1})/5 \\end{cases} \\] La diferencia está en que apenas calcula un nuevo valor de las incógnitas, Gauss-Seidel lo usa inmediatamente en el cálculo de las restantes, en lugar esperar a la próxima ronda. Tomando otra vez el valor inicial \\((1, 2, 2)\\) y operando con 4 posiciones decimales con redondeo luego de la coma: Jacobi Gauss-Seidel \\(k\\) \\(x_k\\) \\(y_k\\) \\(z_k\\) \\(k\\) \\(x_k\\) \\(y_k\\) \\(z_k\\) 0 1 2 2 0 1 2 2 1 1.7500 3.3750 3.0000 1 1.7500 3.7500 2.9500 2 1.8438 3.8750 3.0250 2 1.9500 3.9688 2.9862 3 1.9625 3.9250 2.9625 3 1.9957 3.9961 2.9991 4 1.9906 3.9766 3.0000 4 1.9993 3.9995 2.9998 5 1.9942 3.9953 3.0009 5 1.9999 3.9999 3.0000 6 1.9986 3.9972 2.9986 6 2.0000 4.0000 3.0000 7 1.9997 3.9991 3.0000 8 1.9998 3.9999 3.0001 9 2.0000 3.9999 2.9999 10 2.0000 4.0000 3.0000 3.9.3 Generalización Ahora que sabemos qué hace cada método y en qué se diferencian, vamos a generalizar las fórmulas recursivas. Pensemos en un sistema de \\(n\\) ecuaciones lineales con \\(n\\) incógnitas y despejamos una variable en cada ecuación: \\[ \\begin{cases} a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n = b_1 \\\\ a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n = b_2 \\\\ \\vdots \\\\ a_{j1}x_1 + a_{j2}x_2 + \\cdots + a_{jn}x_n = b_j \\\\ \\vdots \\\\ a_{n1}x_1 + a_{n2}x_2 + \\cdots + a_{nn}x_n = b_n \\end{cases} \\] \\[ \\implies\\hspace{-0.2cm} \\begin{cases} x_1 = \\frac{b_1 - a_{12}x_2 - \\cdots - a_{1n}x_n}{ a_{11}}\\\\ x_2 = \\frac{b_2 - a_{21}x_1 - a_{23}x_3 - \\cdots - a_{2n}x_n}{ a_{22}}\\\\ \\vdots \\\\ x_j = \\frac{b_j - a_{j1}x_1 \\cdots - a_{j(j-1)}x_{j-1} - a_{j(j+1)}x_{j+1} - \\cdots - a_{jn}x_n}{ a_{jj}}\\\\ \\vdots \\\\ x_n = \\frac{b_n - a_{n1}x_1 - \\cdots - a_{n(n-1)}x_{n-1}}{a_{nn}}\\\\ \\end{cases} \\] Generalización del Método de Jacobi Con los supra índices indicando el número de iteración, la fórmula de recurrencia es: \\[ \\begin{cases} x_1^{(k+1)} = \\frac{b_1 - a_{12}x_2^{(k)} - \\cdots - a_{1n}x_n^{(k)}}{ a_{11}}\\\\ x_2^{(k+1)} = \\frac{b_2 - a_{21}x_1^{(k)} - a_{23}x_3^{(k)} - \\cdots - a_{2n}x_n^{(k)}}{ a_{22}}\\\\ \\vdots \\\\ x_j^{(k+1)} = \\frac{b_j - a_{j1}x_1^{(k)} \\cdots - a_{j(j-1)}x_{j-1}^{(k)} - a_{j(j+1)}x_{j+1}^{(k)} - \\cdots - a_{jn}x_n^{(k)}}{ a_{jj}}\\\\ \\vdots \\\\ x_n^{(k+1)} = \\frac{b_n - a_{n1}x_1^{(k)} - \\cdots - a_{n(n-1)}x_{n-1}^{(k)}}{a_{nn}}\\\\ \\end{cases} \\] \\[ \\implies x_j^{(k+1)} = \\frac{b_j - a_{j1}x_1^{(k)} \\cdots - a_{j(j-1)}x_{j-1}^{(k)} - a_{j(j+1)}x_{j+1}^{(k)} - \\cdots - a_{jn}x_n^{(k)}}{ a_{jj}} \\] \\[ k=1, 2, \\cdots n \\] Generalización del Método de Gauss-Seidel Con los supra índices indicando el número de iteración, la fórmula de recurrencia es: \\[ \\begin{cases} x_1^{(k+1)} = \\frac{b_1 - a_{12}x_2^{(k)} - \\cdots - a_{1n}x_n^{(k)}}{ a_{11}}\\\\ x_2^{(k+1)} = \\frac{b_2 - a_{21}x_1^{(k+1)} - a_{23}x_3^{(k)} - \\cdots - a_{2n}x_n^{(k)}}{ a_{22}}\\\\ \\vdots \\\\ x_j^{(k+1)} = \\frac{b_j - a_{j1}x_1^{(k+1)} \\cdots - a_{j(j-1)}x_{j-1}^{(k+1)} - a_{j(j+1)}x_{j+1}^{(k)} - \\cdots - a_{jn}x_n^{(k)}}{ a_{jj}}\\\\ \\vdots \\\\ x_n^{(k+1)} = \\frac{b_n - a_{n1}x_1^{(k+1)} - \\cdots - a_{n(n-1)}x_{n-1}^{(k+1)}}{a_{nn}}\\\\ \\end{cases} \\] \\[ \\implies x_j^{(k+1)} = \\frac{b_j - a_{j1}x_1^{(k+1)} \\cdots - a_{j(j-1)}x_{j-1}^{(k+1)} - a_{j(j+1)}x_{j+1}^{(k)} - \\cdots - a_{jn}x_n^{(k)}}{ a_{jj}} \\] \\[ k=1, 2, \\cdots n \\] 3.9.4 Expresión matricial Ahora vamos a ver que es posible escribir las fórmulas recursivas anteriores de manera matricial, de modo que sea más fácil programar estos métodos. Tarea: corroborar con un sistema pequeño la coincidencia entre los procesos iterativos mencionados en la sección anterior y la iteración con matrices como se muestra a continuación. Ver ambos algoritmos y programar el de Gauss-Seidel. Expresión matricial para el Método de Jacobi Si descomponemos a la matriz \\(\\mathbf{A}\\) como \\(\\mathbf{A=D+R}\\), donde \\(\\mathbf{D}\\) es la matriz diagonal formada con la diagonal de \\(\\mathbf{A}\\) y \\(\\mathbf{R}\\) es igual a \\(\\mathbf{A}\\) excepto en la diagonal donde posee todos ceros, tenemos: \\[\\begin{align*} \\mathbf{Ax} &amp;= \\mathbf{b} \\\\ \\mathbf{(D+R)x} &amp;= \\mathbf{b} \\\\ \\mathbf{Dx} &amp;= \\mathbf{b} - \\mathbf{Rx} \\\\ \\mathbf{x} &amp;= \\mathbf{D}^{-1} (\\mathbf{b} - \\mathbf{Rx}) \\\\ \\end{align*}\\] Esto da lugar a la siguiente fórmula de recurrencia, que es equivalente a las vistas anteriormente y facilita la programación del método: \\[ \\mathbf{x}^{(k+1)} = \\mathbf{D}^{-1} (\\mathbf{b} - \\mathbf{Rx}^{(k)}) \\] Requisito: ningún elemento en la diagonal de \\(\\mathbf{A}\\) es cero. Expresión matricial para el Método de Gauss-Seidel Si descomponemos a la matriz \\(\\mathbf{A}\\) como \\(\\mathbf{A=L+U}\\), donde \\(\\mathbf{L}\\) es una matriz triangular inferior (incluyendo la diagonal de \\(\\mathbf{A}\\)) y \\(\\mathbf{U}\\) es una matriz triangular superior (con ceros en la diagonal), tenemos: \\[\\begin{align*} \\mathbf{Ax} &amp;= \\mathbf{b} \\\\ \\mathbf{(L+U)x} &amp;= \\mathbf{b} \\\\ \\mathbf{Lx} &amp;= \\mathbf{b} - \\mathbf{Ux} \\\\ \\mathbf{x} &amp;= \\mathbf{L}^{-1} (\\mathbf{b} - \\mathbf{Ux}) \\\\ \\end{align*}\\] Esto da lugar a la siguiente fórmula de recurrencia, que es equivalente a las vistas anteriormente, y facilita la programación del método: \\[ \\mathbf{x}^{(k+1)} = \\mathbf{L}^{-1} (\\mathbf{b} - \\mathbf{Ux}^{(k)}) \\] Requisito: ningún elemento en la diagonal de \\(\\mathbf{A}\\) es cero. 3.9.5 Convergencia Definición Se dice que una matriz \\(\\mathbf{A}\\) de orden \\(n \\times n\\) es diagonal estrictamente dominante cuando cada elemento diagonal es mayor a la suma del resto de los elementos de su fila en valor absoluto: \\[ |a_{kk}| &gt; \\sum\\limits_{\\substack{j=0 \\\\ j\\neq k}}^n |a_{kj}| \\quad k=1, 2, \\cdots, n \\] Teorema Si la matriz \\(\\mathbf{A}\\) es diagonal estrictamente dominante, entonces el sistema lineal \\(\\mathbf{Ax=b}\\) tiene solución única y los procesos iterativos de Jacobi y de Gauss-Seidel convergen hacia la misma solución cualquiera sea el vector de partida \\(\\mathbf{x_0}\\). Es una condición suficiente pero no necesaria. En la práctica, ante un sistema buscamos reordenar las columnas y filas para intentar obtener una matriz con estas características. Si no es posible, igualmente buscamos colocar en la diagonal los elementos de mayor valor absoluto, puesto que esto puede favorecer a la convergencia. Criterios para la convergencia Norma L1 (distancia Manhattan): \\[ ||\\mathbf{x}_{k+1}-\\mathbf{x}_{k}||_1 =\\sum_{j=1}^n |x_j^{(k+1)} - x_j^{(k)}| &lt; \\epsilon \\] Norma L2 (norma euclídea): \\[||\\mathbf{x}_{k+1}-\\mathbf{x}_{k}||_2 = \\sqrt{(\\mathbf{x}_{k+1}-\\mathbf{x}_{k})&#39;(\\mathbf{x}_{k+1}-\\mathbf{x}_{k})} = \\sqrt{\\sum_{j=1}^n (x_j^{(k+1)} - x_j^{(k)})^2} &lt; \\epsilon\\] Norma L\\(_\\infty\\) (máxima diferencia): \\[ ||\\mathbf{x}_{k+1}-\\mathbf{x}_{k}||_\\infty = \\max_{j} |x_j^{(k+1)} - x_j^{(k)}| &lt; \\epsilon \\] Establecer un número máximo de iteraciones Ventajas de Gauss-Seidel Converge más rápidamente. Puede converger cuando Jacobi no lo hace (aunque \\(\\mathbf{A}\\) no sea diagonal estrictamente dominante, por ejemplo si \\(\\mathbf{A}\\) es semidefinida positiva). Pero puede haber casos en los que Jacobi converge y Gauss-Seidel no. "]
]
